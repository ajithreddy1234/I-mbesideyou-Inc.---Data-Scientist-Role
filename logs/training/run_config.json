{
  "model_name": "google/flan-t5-base",
  "lora_dir": "artifacts/flan_t5_minutes_lora",
  "context_len": 512,
  "target_len": 256,
  "seed": 42,
  "train_size": 118,
  "val_size": 2,
  "learning_rate": 0.0002,
  "weight_decay": 0.01,
  "warmup_ratio": 0.1,
  "epochs": 4,
  "per_device_train_batch_size": 2,
  "chunk_long_dialogues": true,
  "chunk_overlap": 128,
  "use_gradient_checkpointing": false,
  "device": "mps"
}